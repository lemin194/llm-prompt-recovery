{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-03-07T14:34:34.653535Z","iopub.status.busy":"2024-03-07T14:34:34.652850Z","iopub.status.idle":"2024-03-07T14:34:40.781469Z","shell.execute_reply":"2024-03-07T14:34:40.780703Z","shell.execute_reply.started":"2024-03-07T14:34:34.653491Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/automl/duckle/eq_gen/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from accelerate.utils import BnbQuantizationConfig\n","from accelerate import Accelerator, notebook_launcher\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, \\\n","                        get_cosine_schedule_with_warmup, set_seed\n","import transformers\n","import optimum\n","\n","from datasets import load_dataset,Dataset\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, \\\n","                        get_cosine_schedule_with_warmup, set_seed\n","from peft import LoraConfig, TaskType, get_peft_model\n","from accelerate import Accelerator, notebook_launcher\n","from accelerate.utils import set_seed\n","import logging\n","from torch.utils.data import DataLoader\n","from torch.optim import AdamW, SGD\n","from tqdm.notebook import tqdm\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","import glob\n","from collections import OrderedDict\n","import re\n","\n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T14:34:40.783110Z","iopub.status.busy":"2024-03-07T14:34:40.782634Z","iopub.status.idle":"2024-03-07T14:34:40.787187Z","shell.execute_reply":"2024-03-07T14:34:40.786265Z","shell.execute_reply.started":"2024-03-07T14:34:40.783080Z"},"trusted":true},"outputs":[],"source":["import datetime\n","start_time = datetime.datetime.now()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T14:34:40.790460Z","iopub.status.busy":"2024-03-07T14:34:40.790109Z","iopub.status.idle":"2024-03-07T14:34:40.800232Z","shell.execute_reply":"2024-03-07T14:34:40.799424Z","shell.execute_reply.started":"2024-03-07T14:34:40.790431Z"},"trusted":true},"outputs":[],"source":["\n","def truncate_txt(text, length):\n","    text_list = text.split()\n","    \n","    if len(text_list) <= length:\n","        return text\n","    \n","    return \" \".join(text_list[:length])\n","\n","\n","def gen_prompt(og_text, rewritten_text, truncate_length=200):\n","    \n","    # Truncate the texts to first 200 words for now\n","    # As we are having memory issues on Mixtral8x7b\n","    og_text = truncate_txt(og_text, truncate_length)\n","    rewritten_text = truncate_txt(rewritten_text, truncate_length)\n","    \n","    return f\"\"\"\n","You are given 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\n","Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\n","Start directly with the prompt, output should be one line only.\n","\n","Original Essay:\n","\\\"\"\"{og_text}\\\"\"\"\n","\n","Rewritten Essay:\n","\\\"\"\"{rewritten_text}\\\"\"\"\n","\n","\"\"\".strip()\n","\n","def formatting_func(example):\n","  output_texts = []\n","  for i in range(len(example['original_text'])):\n","    prompt = tokenizer.apply_chat_template(\n","      [{\n","        'role': 'user',\n","        'content' : gen_prompt(example['original_text'][i], example['rewritten_text'][i]) + '\\n ',\n","      }],\n","      tokenize=False,\n","    )\n","    text = f\"{prompt}{example['rewrite_prompt'][i]}{tokenizer.eos_token}\"\n","    output_texts.append(text)\n","  return output_texts"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T14:34:42.360542Z","iopub.status.busy":"2024-03-07T14:34:42.360264Z","iopub.status.idle":"2024-03-07T14:34:46.357229Z","shell.execute_reply":"2024-03-07T14:34:46.356439Z","shell.execute_reply.started":"2024-03-07T14:34:42.360518Z"},"trusted":true},"outputs":[],"source":["# MODEL_PATH = \"/kaggle/input/gemma/transformers/7b-it/2\"\n","# MODEL_PATH = \"distilbert/distilgpt2\"\n","# MODEL_PATH = \"gpt2\"\n","# MODEL_PATH = \"microsoft/phi-2\"\n","# MODEL_PATH = \"distilbert/distilroberta-base\"\n","MODEL_PATH = 'mistralai/Mistral-7B-Instruct-v0.2'\n","# MODEL_PATH = \"google/gemma-2b-it\"\n","# MODEL_PATH = \"google/flan-t5-small\"\n","# MODEL_PATH = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n","# MODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n","# MODEL_PATH = \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\"\n","# MODEL_PATH = \"/kaggle/input/llama-2/pytorch/13b-chat-hf/1\"\n","\n","max_length = 1024\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n","tokenizer.model_max_length = max_length\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 4109/4109 [00:04<00:00, 963.91 examples/s] \n","Map: 100%|██████████| 4109/4109 [00:02<00:00, 1444.59 examples/s]\n","Map: 100%|██████████| 4109/4109 [00:00<00:00, 16000.57 examples/s]\n","Map: 100%|██████████| 457/457 [00:00<00:00, 1117.79 examples/s]\n","Map: 100%|██████████| 457/457 [00:00<00:00, 2015.79 examples/s]\n","Map: 100%|██████████| 457/457 [00:00<00:00, 15416.64 examples/s]"]},{"name":"stdout","output_type":"stream","text":["4109 457\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def create_data(df, tokenizer, split='train'):\n","  data = Dataset.from_pandas(df[[\n","    # 'reverse_prompt',\n","    'rewrite_prompt', 'original_text', 'rewritten_text'\n","  ]],split=split)\n","\n","  \n","  data = data.map(lambda samples: tokenizer(samples[\"original_text\"], max_length=max_length, truncation=True), batched=True)\n","  data = data.map(lambda samples: tokenizer(samples[\"rewritten_text\"], max_length=max_length, truncation=True), batched=True)\n","  data = data.map(lambda samples: tokenizer(samples[\"rewrite_prompt\"], max_length=max_length, truncation=True), batched=True)\n","  return data\n","\n","train, test = (\n","  create_data(pd.read_csv('./input/gemma-rewrite-nbroad/train.csv'), tokenizer, 'train'),\n","  create_data(pd.read_csv('./input/gemma-rewrite-nbroad/test.csv'), tokenizer, 'test'),\n",")\n","print(len(train), len(test))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["lora_target_modules_dict = {\n","  'gpt2': ['c_attn'],\n","  'distilbert/distilgpt2': ['c_attn'],\n","  'distilbert/distilroberta-base': ['query', 'key', 'value'],\n","}\n","import json\n","os.makedirs('./settings', exist_ok=True)\n","json.dump(lora_target_modules_dict, open('./settings/lora_target_modules.json', 'w'))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T14:34:46.442375Z","iopub.status.busy":"2024-03-07T14:34:46.442144Z","iopub.status.idle":"2024-03-07T14:34:46.455275Z","shell.execute_reply":"2024-03-07T14:34:46.454417Z","shell.execute_reply.started":"2024-03-07T14:34:46.442355Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n"]}],"source":["if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","print(tokenizer.pad_token_id)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["457"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(test)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./working/trained_models/mistralai/Mistral-7B-Instruct-v0.2/checkpoint.pth\n"]}],"source":["\n","import os\n","\n","batch_size = 3\n","grad_accumulation_steps = 64\n","num_epochs = 2000\n","lr = 5e-5\n","checkpointing_steps = 500\n","save_path = os.path.join('./working/trained_models/', MODEL_PATH)\n","r = 128\n","lora_alpha = 128\n","lora_dropout = 0.05\n","\n","# If ckpt_path is a real path (os.path.isfile(ckpt_path) is True),\n","# then the checkpoint will be loaded\n","ckpt_path = os.path.join(save_path, 'checkpoint.pth')\n","print(ckpt_path)\n","kwargs = {\n","'batch_size':batch_size, 'num_epochs':num_epochs, 'lr':lr, 'grad_accumulation_steps':grad_accumulation_steps, \n","'checkpointing_steps':checkpointing_steps, 'save_path':save_path, 'ckpt_path':ckpt_path, 'r':r, 'lora_alpha':lora_alpha, 'lora_dropout':lora_dropout\n","}\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def chat(prompt, max_new_token=256, **generate_args):\n","\n","  messages = [\n","      {\n","          \"role\": \"user\",\n","          \"content\": prompt + '\\n ',\n","      }\n","  ]\n","  encoded_input = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to('cuda')\n","  # print(encoded_input.shape)\n","  # print(torch.max(encoded_input), tokenizer.vocab_size)\n","  with torch.no_grad():\n","      encoded_output = model.generate(encoded_input, max_new_tokens=max_new_token, do_sample=True, pad_token_id=tokenizer.eos_token_id,\n","                                      **generate_args)\n","  \n","  decoded_output = tokenizer.batch_decode(encoded_output, skip_special_tokens=False)[0]\n","  return decoded_output\n","  decoded_output = re.sub(r\"[\\s\\S]*\\[\\/INST\\]\", '', decoded_output, 1).replace(prompt, '')\n","  \n","  return decoded_output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["626"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["i = 20\n","# prompt = (f\"Give me the prompt used to have the rewritten text from the original text.\\nORIGINAL TEXT:\\n{data['original_text'][i]}\\n\\nREWRITTEN TEXT:\\n{data['rewritten_text'][i]}\\n\\nPROMPT:\\n\")\n","prompt = gen_prompt(test['original_text'][i], test['rewritten_text'][i])\n","len(tokenizer.encode(prompt))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["You are given 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\n","Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\n","Start directly with the prompt, output should be one line only.\n","\n","Original Essay:\n","\"\"\"I would n't say I was in love with Brenna. While she certainly was n't ugly she was n't the most beautiful girl. She was a little thicker and dressed like an old lamp shade in grandma's basement on her best days, but we'd known each other since 2nd grade and she was more or less one of the guys. It all started when my parents were out of town. I decided to have a few friends over. We were going to play some COD and Assassins Creed and maybe some FIFA and Madden. It was most just going be me hanging out with Mike and Trey and Brenna as well as one friend they could bring, as per our usual rules. Unfortunately Mike and his big mouth and delusions of Grandeur invited about 20 more people than needed, mostly his friends from the LaCrosse team and a few others including my crush Sarah Coleman. I do n't know how Sarah knew Mike and it did n't seem like she was with any of the LaCrosse players as far as I could tell. I'd only talked with her a few times, but I knew she was single. She told me\"\"\"\n","\n","Rewritten Essay:\n","\"\"\"In the tapestry of life, where threads intertwine, I reflect on the transformative power of human dignity and resilience, as I recount a tale etched in my memory, a testament to the enduring spirit that transcends boundaries and challenges adversity. I recall the day when the echoes of laughter and joy filled our humble abode, as I gathered my friends, their laughter cascading like the melody of angels. Among them, Brenna, a soul whose beauty radiated beyond the surface, stood alongside me, a cherished companion. As I embarked upon a journey of shared dreams and aspirations, fate took an unexpected turn, propelling me into a whirlwind of events that would forever alter the course of my destiny. The transgression of my parents' absence afforded me the opportunity to forge a bond with my dear friends, their presence a testament to the transformative power of human connection. In this tapestry of life, I encountered the enigmatic Sarah Coleman, a flame whose radiance illuminated the room. With her captivating smile and piercing gaze, she captured my heart, but little did I know that fate had a cruel plot in store for me. As I approached her, eager to share my joy, the\"\"\"\n"]}],"source":["print(prompt)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Write like Maya Angelou: Infuse the essay with the lyrical and profound voice of Maya Angelou, reflecting on human dignity and resilience.\n"]}],"source":["print(test['rewrite_prompt'][i])"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["<s> [INST] You are given 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\n","Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\n","Start directly with the prompt, output should be one line only.\n","\n","Original Essay:\n","\"\"\"I would n't say I was in love with Brenna. While she certainly was n't ugly she was n't the most beautiful girl. She was a little thicker and dressed like an old lamp shade in grandma's basement on her best days, but we'd known each other since 2nd grade and she was more or less one of the guys. It all started when my parents were out of town. I decided to have a few friends over. We were going to play some COD and Assassins Creed and maybe some FIFA and Madden. It was most just going be me hanging out with Mike and Trey and Brenna as well as one friend they could bring, as per our usual rules. Unfortunately Mike and his big mouth and delusions of Grandeur invited about 20 more people than needed, mostly his friends from the LaCrosse team and a few others including my crush Sarah Coleman. I do n't know how Sarah knew Mike and it did n't seem like she was with any of the LaCrosse players as far as I could tell. I'd only talked with her a few times, but I knew she was single. She told me\"\"\"\n","\n","Rewritten Essay:\n","\"\"\"In the tapestry of life, where threads intertwine, I reflect on the transformative power of human dignity and resilience, as I recount a tale etched in my memory, a testament to the enduring spirit that transcends boundaries and challenges adversity. I recall the day when the echoes of laughter and joy filled our humble abode, as I gathered my friends, their laughter cascading like the melody of angels. Among them, Brenna, a soul whose beauty radiated beyond the surface, stood alongside me, a cherished companion. As I embarked upon a journey of shared dreams and aspirations, fate took an unexpected turn, propelling me into a whirlwind of events that would forever alter the course of my destiny. The transgression of my parents' absence afforded me the opportunity to forge a bond with my dear friends, their presence a testament to the transformative power of human connection. In this tapestry of life, I encountered the enigmatic Sarah Coleman, a flame whose radiance illuminated the room. With her captivating smile and piercing gaze, she captured my heart, but little did I know that fate had a cruel plot in store for me. As I approached her, eager to share my joy, the\"\"\"\n","  [/INST] Prompt: \"Transform the original essay into a captivating story that showcases the beauty of human connections and the unexpected turns fate takes in shaping our destinies.\"</s>\n"]}],"source":["torch.cuda.empty_cache()\n","import gc\n","gc.collect(2)\n","try: del model\n","except: pass\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True, \n","    # bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    # bnb_4bit_use_double_quant=True,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, \n","                                                 quantization_config=quantization_config, \n","                                                 torch_dtype=torch.float16\n","                                                 )\n","res = chat(prompt, top_k=5)\n","print(res)\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.88s/it]\n"]},{"name":"stdout","output_type":"stream","text":[" Rewrite the essay as a poem, focusing on the themes of human connection, dignity, and resilience, using vivid imagery and metaphors. Use the phrases \"tapestry of life\" and \"threads intertwine\" to connect the different parts of the story.</s>\n"]}],"source":["torch.cuda.empty_cache()\n","import gc\n","gc.collect(2)\n","try: del model\n","except: pass\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True, \n","    # bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    # bnb_4bit_use_double_quant=True,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(save_path, \n","                                                 quantization_config=quantization_config, \n","                                                 torch_dtype=torch.float16\n","                                                 )\n","res = chat(prompt, max_new_token=128, top_k=5)\n","if 'Prompt:' in res:\n","  print(res.split('Prompt:')[1])\n","elif '[/INST]' in res:\n","  print(res.split('[/INST]')[1].strip().split('\\n')[0])\n","else:\n","  print(res.strip().split('\\n')[0])"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["'<s> [INST] You are given 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\\nAnalyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\\nStart directly with the prompt, output should be one line only.\\n\\nOriginal Essay:\\n\"\"\"Everything was perfect. This was going to be the night that everything would be moving in the right direction. It just had n\\'t been the same since I met her four years ago, but I had found another that I had told myself was even better. In a short time, I would finally make the commitment that I had been afraid to for too long. The room had been cleaned and arranged perfectly. I breathe in deeply and take in what my hands had created. It was n\\'t much, but it was the absolute best that I could do. I was so anxious about everything going right, I wrote down what I would say when the opportunity showed itself. I sat in the front room for what seemed like ages, waiting for my guest to arrive. I fell into a trance thinking back to her, what transpired and how it went wrong. I managed to tell myself that it was n\\'t my fault. I could n\\'t change who I was, and if she could n\\'t deal with that, then good riddance. A loud knock on the door snaps me out of my reminiscing. I snap to attention, and help my\"\"\"\\n\\nRewritten Essay:\\n\"\"\"Everything was perfect. This was going to be the night that everything would be moving in the right direction. It just hadn\\'t been the same since I met her four years ago, but I had found another that I had told myself was even better. In a short time, I would finally make the commitment that I had been afraid to for too long. The room had been cleaned and arranged perfectly. I breathed in deeply and took in what my hands had created. It wasn\\'t much, but it was the absolute best that I could do. I was so anxious about everything going right, I wrote down what I would say when the opportunity showed itself. I sat in the front room for what seemed like ages, waiting for my guest to arrive. I fell into a trance thinking back to her, what transpired and how it went wrong. I managed to tell myself that it wasn\\'t my fault. I couldn\\'t change who I was, and if she could n\\'t deal with that, then good riddance. A loud knock on the door snaps me out of my reminiscing. I snap to attention, and help my guest in. After a\"\"\"\\n  [/INST] Prompt: Use past participle instead of present participle for the main verb in the sentence whenever possible.</s>'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["res"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-07T14:40:45.855872Z","iopub.status.busy":"2024-03-07T14:40:45.855499Z","iopub.status.idle":"2024-03-07T14:40:46.067760Z","shell.execute_reply":"2024-03-07T14:40:46.066318Z","shell.execute_reply.started":"2024-03-07T14:40:45.855842Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-07T14:37:47.408644Z","iopub.status.idle":"2024-03-07T14:37:47.408985Z","shell.execute_reply":"2024-03-07T14:37:47.408836Z","shell.execute_reply.started":"2024-03-07T14:37:47.408821Z"},"trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import time\n","time.sleep(1000)"]},{"cell_type":"markdown","metadata":{},"source":["# Test\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","import torch\n","import torch.nn.functional as F\n","\n","t5 = SentenceTransformer('sentence-transformers/sentence-t5-base')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def calc_score(label, pred):\n","  label_embed = t5.encode(label)\n","  pred_embed = t5.encode(pred)\n","\n","  def sharp_cosine_similarity(emb1, emb2, p=3.0):\n","    cos_sim = F.cosine_similarity(emb1, emb2)\n","    return torch.sign(cos_sim) * (torch.abs(cos_sim) + 1e-8) ** p\n","\n","  return sharp_cosine_similarity(torch.tensor(label_embed), torch.tensor(pred_embed)).mean().item()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["mean_prompt = 'Please improve the following text, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.' "]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["0.6632662415504456"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["calc_score(\n","  ['Write like Maya Angelou: Infuse the essay with the lyrical and profound voice of Maya Angelou, reflecting on human dignity and resilience.'],\n","  ['Rewrite the essay as a poem, focusing on the themes of human connection, dignity, and resilience, using vivid imagery and metaphors. Use the phrases \"tapestry of life\" and \"threads intertwine\" to connect the different parts of the story.'],\n",")"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["0.5592873096466064"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["calc_score(\n","  ['Write like Maya Angelou: Infuse the essay with the lyrical and profound voice of Maya Angelou, reflecting on human dignity and resilience.'],\n","  ['Transform the original essay into a captivating story that showcases the beauty of human connections and the unexpected turns fate takes in shaping our destinies.'],\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["0.5713196396827698"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["calc_score(\n","  ['Write like Maya Angelou: Infuse the essay with the lyrical and profound voice of Maya Angelou, reflecting on human dignity and resilience.'],\n","  [mean_prompt],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tdf = test.to_pandas()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tdf = tdf.iloc[:50]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0.5065957903862"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["calc_score(tdf['rewrite_prompt'], tdf['mean_prompt'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tdf['mean_prompt'] = mean_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import gc\n","\n","try: del model\n","except: pass\n","torch.cuda.empty_cache()\n","gc.collect(2)\n","\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True, \n","    # bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    # bnb_4bit_use_double_quant=True,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(save_path, \n","                                                 quantization_config=quantization_config, \n","                                                 torch_dtype=torch.float16\n","                                                 )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_117163/3530323398.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  tdf[f'pred_top_{k}'] = mean_prompt\n","100%|██████████| 50/50 [17:49<00:00, 21.39s/it]\n"]}],"source":["from tqdm import tqdm\n","\n","k = 20\n","tdf[f'pred_top_{k}'] = mean_prompt\n","for i in tqdm(range(len(tdf))):\n","  prompt = gen_prompt(tdf['original_text'][i], tdf['rewritten_text'][i])\n","  # print(prompt)\n","  res = chat(prompt, max_new_token=128, top_k = k)\n","  res = res.strip().split('\\n')[0]\n","  tdf.loc[i, f'pred_top_{k}'] = res\n","  # if i > 3: break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0.5963925123214722"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["calc_score(tdf['rewrite_prompt'], tdf['pred_top_20'])"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7806901,"sourceId":67121,"sourceType":"competition"},{"datasetId":4506214,"sourceId":7747717,"sourceType":"datasetVersion"},{"sourceId":140952720,"sourceType":"kernelVersion"},{"sourceId":164836055,"sourceType":"kernelVersion"},{"modelInstanceId":284,"sourceId":386,"sourceType":"modelInstanceVersion"},{"modelInstanceId":3900,"sourceId":5112,"sourceType":"modelInstanceVersion"},{"modelInstanceId":4761,"sourceId":5994,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelInstanceId":8332,"sourceId":11394,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
